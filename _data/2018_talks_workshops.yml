- speaker: "Sacha Verweij and Jane Herriman"
  avatar: https://avatars3.githubusercontent.com/u/5799177?s=460&v=4
  affiliation: "Stanford University and Julia Computing"
  title: "An Introduction to Julia"
  type: workshop
  abstract: >
    Are you new to Julia?! This beginners’ tutorial should be accessible to anyone with technical computing needs and some experience with another language. We will show you why Julia is special, demonstrate how easy Julia is to learn, and get you writing some Julia code.
  desc: |
    Are you new to Julia?! This introductory workshop should be accessible to anyone with technical computing needs and some experience with another programming language. We will show you why Julia is special, demonstrate how easy Julia is to learn, and get you writing Julia code.

    In the first half of this tutorial, we will briefly introduce the language, giving attendees a sense of why Julia is special and what needs Julia meets. After that, we will show how easy it is to pick up Julia’s syntax, covering string manipulation, data structures, loops, conditionals, and functions.

    In the second half of this tutorial, we will illustrate Julia’s speed, power, and expressiveness. Among other things, we will look at Julia’s generic linear algebra infrastructure, benchmark Julia against C and Python, and discuss how Julia’s design paradigm leads to flexible performance.

    Exercises to ingrain concepts will be included throughout the tutorial with an integrative exercise at the end.
  bio: |
    Jane Herriman is Director of Diversity and Outreach at Julia Computing and a PhD student in the Department of Applied Physics and Materials Science at Caltech. She has completed part of her PhD at Lawrence Livermore National Lab.

    Sacha Verweij has recently completed his PhD in Applied Physics and Computational Mathematics at Stanford University, and is a core developer of the Julia language.
  id: 1

- speaker: "Andy Ferris"
  avatar: https://avatars3.githubusercontent.com/u/2974526?s=460&v=4
  affiliation: "Fugro Roames"
  title: "A practical introduction to metaprogramming in Julia"
  type: workshop
  abstract: >
    Julia focuses on speed and user productivity, due in part to its metaprogramming capability. This workshop arms you with the knowledge to create fast, generic and easy-to-use APIs using techniques including multiple dispatch, recursion, traits, constant propagation, macros, and generated functions.
  desc: |
    In many programming environments, user friendliness must be traded of with execution speed. Using abstractions or “generic” code may come with a run-time overhead. Avoiding abstract or generic code exposes the user to underlying details that they may not care about, making code harder to read and reason about at a higher level, reducing programmer productivity. Often two languages are even employed - one for rapid prototyping, and one for deployment.

    It doesn’t have to be this way. The Julia language has been carefully constructed to allow for many common abstractions to be dealt with statically at compile time and have a have a zero run-time cost. This workshop will cover the topic of “metaprogramming” in Julia, which plays a large role in providing for low-cost abstractions and generic APIs. Traditionally, a “meta” program is logic which executes at compile time to help generate the code of a resulting program - that is, it is code that generates other code.

    In this workshop we will cover the building blocks of metaprogramming in Julia, starting with one of its core concepts - multiple dispatch, which in combination with the type system is itself is a Turing-complete computational environment. We will then begin working our way to more advanced topics such as traits, macros, constant propagation and generated functions, following approximately this order:

    * Multiple dispatch as a metaprogramming technique
    * Method inlining: faster than C
    * Games with tuples: splatting, slurping and recursion
    * Dispatch revisited: traits
    * Constant propagation (and what are @pure functions?)
    * Expressions and macros
    * Generated functions and when (not) to use them
    * This workshop will attempt to be a pedagogical tutorial on how and when to use these techniques, full of practical examples I’ve seen in the wild or have used in my own code. Consideration will be given in how to use metaprogramming and still maintain a readable code base. Advice will also be provided on how to work with the compiler, and not against it, and how to make effective use of tools such as @code_typed. At the end of the workshop I hope you will have learned a technique or two that will help you to create generic, user-friendly APIs without sacrificing peak performance.
  bio: |
    I am an algorithm and software engineer at Fugro Roames, applying machine learning techniques to big data in order to make sense of and to model the physical world. I have been using Julia since v0.3 for both research and commercial production-at-scale, and am the author of several Julia packages including StaticArrays.
  id: 2

- speaker: "Pontus Stenetorp"
  avatar: https://avatars1.githubusercontent.com/u/354934?s=460&v=4
  affiliation: "University College London"
  title: "Machine Learning with Julia: Elegance, Speed and Ease"
  type: workshop
  abstract: >
    Machine Learning has become one of the hottest research and industry areas over the last few years; we believe Julia is the strongest contender to become the language for Machine Learning and in this tutorial we will give a flying start to train/deploy models and use of the power that Julia brings.
  desc: |
    Machine Learning (ML) is at its core the art of programming by data, rather than by hand, and ML has risen to become one of the most desirable skills in academia and industry. The common maxim is that two traits control who rules the ML landscape, ability to find and ingest more data and those that can innovate the quickest. Given these traits, we argue that Julia is uniquely poised as a very strong contender as the language for ML; as we allow for quick development cycles and offer unrivalled speed. After a quick introduction to the basics of ML, we will give the audience a description of the lay of the land in terms of libraries and frameworks in Julia, and finally proceed to build simple to complex models using the premier framework Flux. After attending the workshop the audience will be familiar with the basics of ML to avoid common pitfalls and be ready to tackle their own ML problems the Julian way.
  bio: |
    I am Pontus Stenetorp, a researcher and educator that finds Natural Language Processing (NLP) and Machine Learning research to be fascinating. The widely-adopted text annotation and visualisation tool brat is one of my creations and since 2012 a majority of my work has been on representation learning (Deep Learning) for natural language.

    My current research focuses on end-to-end models that learns with a minimal amount of human supervision – with a particular focus on allowing computers to pass real-world exams – and is supported by the Paul G Allen Family Foundation. If you share any of my research interests, do have a look at my list of publications and if you have questions regarding my research, feel free to contact me. I also teach and supervise student research projects in my area of expertise.

    Currently, I am a Senior Research Associate at University College London (UCL) and a member of the Machine Reading Group lead by Reader Sebastian Riedel at the Department of Computer Science. I received a PhD from the University of Tokyo in 2013 and a MSc Eng from the Royal Institute of Technology (KTH) in 2010. In my spare time I contribute to the Julia programming language community, read plenty of books, and enjoy being a mediocre amateur photographer.
  resources:
    - name: "Repo"
      url: "http://fluxml.ai/"
  id: 3

- speaker: "Sheehan Olver"
  avatar: https://avatars3.githubusercontent.com/u/1229737?s=400&v=4
  affiliation: "Imperial College, London"
  title: "Numerical Analysis in Julia"
  type: workshop
  abstract: >
    This workshop brings together 5 speakers on different topics in numerical analysis, to demonstrate the strengths of Julia’s approach to scientific computing in atomistic simulations, function approximation, differential equations, fast transformations, validated numerics, and linear algebra.
  desc: |
    This workshop proposal brings together 5 speakers on different topics in numerical analysis. The aim of the workshop is to have demonstrations of Julia packages in this area in a way to motivate the results to a “general” audience. Our speakers cover a variety of areas to give a broad demonstration of what is now possible using Julia.

    Speakers and titles
    -------------------
    * Sheehan Olver: ApproxFun.jl, Approximating Functions and Solving Differential Equations.
    * David P. Sanders: ValidatedNumerics.jl, Rigorous Floating-point Calculations with Interval Arithmetic.
    * R. Mikael Slevinsky: FastTransforms.jl, Fast Orthogonal Polynomial Transforms.
    * Weijian Zhang: MatrixDepot.jl, Testing Linear Algebra Algorithms in Julia.

    Abstracts
    ---------
    *ApproxFun.jl, Approximating Functions and Solving Differential Equations*  
    Sheehan Olver, Imperial College, London

    ApproxFun.jl is a Julia package that makes working with functions on a computer fast and easy. Basic algebra and calculus operations are available, so that one can, for example, differentiate the function $\sin\cos^2 x$ as easy as typing `sin(cos(x)^2)'`. Further capabilities include solving differential equations and random number sampling. This talk will demonstrate the capabilities of ApproxFun, and how Julia’s approach to typing allows for these capabilities to be used with other types, such as Dual numbers (from DualNumbers.jl) or BigFloats.

    *ValidatedNumerics.jl, Rigorous Floating-point Calculations with Interval Arithmetic*  
    David P. Sanders, Universidad Nacional Autónoma de México

    I will present a suite of Julia packages in the JuliaIntervals organisation which provide implementations of numerical methods that provide results that are guaranteed to be correct. These are based on interval arithmetic, i.e. defining arithmetic and elementary functions acting on intervals of real numbers.

    This gives us a tool to calculate with continuous sets of real numbers, and thus rigorously bound the range of a function over a given set. Applications of this technology include finding, in a guaranteed way, all the roots of a multivariable function in a given region of space, and finding the global optimum of a function.

    *FastTransforms.jl, Fast Orthogonal Polynomial Transforms*  
    R. Mikael Slevinsky, University of Manitoba

    FastTransforms.jl allows the user to conveniently work with orthogonal polynomials with degrees well into the millions. Transforms include conversion between Jacobi polynomial expansions, with Chebyshev, Legendre, and ultraspherical polynomial transforms as special cases. For the signal processor, all three types of nonuniform fast Fourier transforms available. As well, spherical harmonic transforms and transforms between orthogonal polynomials on the triangle allow for the efficient simulation of partial differential equations of evolution. Algorithms include methods based on asymptotic formulae to relate the transforms to a small number of fast Fourier transforms, matrix factorizations based on the Hadamard product, hierarchical matrix decompositions à la Fast Multipole Method, and the butterfly algorithm.

    *MatrixDepot.jl, Testing Linear Algebra Algorithms in Julia*  
    Weijian Zhang, University of Manchester

    Test matrices are important for exploring the behavior of linear algebra algorithms and for measuring their performance with respect to accuracy, stability, convergence rate, speed, or robustness. We give a brief historical remark on the development of test matrices in different programming languages and then focus on the advantage of using MatrixDepot.jl for testing and exploring new algorithms in Julia. Using both contrived and real-world examples, we demonstrate the power of MatrixDepot.jl which takes advantage of many nice Julia features, such as using multiple dispatch to help provide a simple user interface and to allow matrices to be generated in any of the numeric data types supported by the language.
  bio: |
    I am a Reader (equivalent to Assoc. Professor) in Applied Mathematics and Mathematical Physics at Imperial College, London. My research is in numerics, in particular spectral methods and complex analytical methods. I have extensive experience with programming Julia, having developed several packages (ApproxFun.jl, BandedMatrices.jl, BlockBandedMatrices.jl, etc.).
  id: 4

- speaker: "David Anthoff"
  avatar: https://avatars2.githubusercontent.com/u/1036561?s=400&v=4
  affiliation: "University of California, Berkeley"
  title: "Queryverse"
  type: workshop
  abstract: >
    This workshop will introduce the Queryverse family of packages, a unified data science stack on julia. It provides tools for file IO, data querying, visual data exploration and statistical plotting. It also integrates with a large number of other julia packages.
  desc: |
    This talk will give an update on the current state of the Queryverse. I will highlight packages for file IO (CSVFiles.jl, ExcelFiles.jl, StatFiles.jl, FeatherFiles.jl, ParquetFiles.jl), querying and manipulating data (Query.jl), visual data exploration (DataVoyager.jl) and graphics (VegaLite.jl). I will show how all of these pieces are designed to work together and provide a unified API for users that spans traditional tabular data and data in custom julia types. I will also highlight how the Queryverse integrates smoothly with all the other julia packages in this space.
  bio: |
    David Anthoff is an environmental economist who studies climate change and environmental policy. He co-develops the integrated assessment model FUND that is used widely in academic research and in policy analysis. His research has appeared in Science, the American Economic Review, Nature Climate Change, the Journal of Environmental Economics and Management, Environmental and Resource Economics, the Oxford Review of Economic Policy and other academic journals. He contributed a background research paper to the Stern Review and has advised numerous organizations (including US EPA and the Canadian National Round Table on the Environment and the Economy) on the economics of climate change.

    He is an assistant professor in the Energy and Resources Group at the University of California at Berkeley, a senior fellow at the Berkeley Institute for Data Science and a University Fellow at Resources for the Future. Previously he was an assistant professor in the School of Natural Resources and Environment at the University of Michigan, a postdoc at the University of California, Berkeley and a postdoc at the Economic and Social Research Institute in Ireland. He also was a visiting research fellow at the Smith School of Enterprise and the Environment, University of Oxford.

    He holds a PhD (Dr. rer. pol.) in economics from the University of Hamburg (Germany) and the International Max Planck Research School on Earth System Modelling, a MSc in Environmental Change and Management from the University of Oxford (UK) and a M.Phil. in philosophy, logic and theory of science from Ludwig-Maximilians-Universität München (Germany).
  resources:
    - name: "Repo"
      url: "https://github.com/davidanthoff/Query.jl"
  id: 5

- speaker: "Chris Rackauckas"
  avatar: https://avatars3.githubusercontent.com/u/1814174?s=460&v=4
  affiliation: "UC Irvine and MIT"
  title: "Solving Partial Differential Equations with Julia "
  type: workshop
  abstract: >
    Climate scientists solve fluid dynamics PDEs. Biologists solve reaction-diffusion PDEs. Economists solve optimal control PDEs. But solving PDEs is hard! Where do you start? This workshop gives a broad overview of the Julia package ecosystem and shows how to tie it together to solve these problems.
  desc: |
    Partial differential equations (PDEs) are used throughout scientific disciplines, modeling diverse phenomena such as the spread of chemical concentrations across biological organisms to global temperature flows. However, solving PDEs efficiently is not easy: it requires a vertical toolkit with many interconnected pieces. In this workshop we will introduce the participants to some basic PDEs, where they come from, and how to tie together the various tools across the Julia package ecosystem to solve them efficiently.

    We will start by focusing on elliptic problems and show how these decompose into solving sparse linear systems. To solve the resulting linear systems, the participants will be introduced three methods: Julia’s special matrix types for efficient dense solutions, BandedMatrices.jl for more generic banded operators, and IterativeSolvers.jl for Krylov methods. The differences between the methodologies and the current status of distributed and GPU compatibility will be discussed. From there, the extension to nonlinear elliptic problems will be shown as effectively solving nonlinear systems with sparse Jacobians, and demonstrations/comparisons of Roots.jl, NLsolve.jl, and Sundials.jl’s KINSOL for solving the resulting systems will be addressed. Lastly, the concept of pseudospectral discretizations will be introduced using the library ApproxFun.jl, it will be shown how this methodology simply leads to different linear/nonlinear systems.

    After understanding the tooling for elliptic PDEs, “time-dependent” PDEs such as parabolic and hyperbolic PDEs will be introduced. It will be shown how similar discretizations as done in the elliptic portion lead to systems of coupled ordinary differential equations (ODEs). It will be demonstrated how to efficiently solve the resulting ODE systems via DifferentialEquations.jl using methods such as via banded Jacobian Rosenbrock integrators, Newton-Krylov BDF, Implicit-Explicit (IMEX) Runge-Kutta, and exponential integrators like ETDRK4. Participants will be shown how to integrate pseudospectral operators from ApproxFun.jl and linear solvers from IterativeSolvers.jl to customize the integrators to their problem. Additionally, special time-stepping issues for hyperbolic PDEs and the strong-stability preserving (SSP) integrators will be introduced.

    Together, the workshop participants should be able to leave with a good understanding of how to tie together the Julia scientific packages to efficiently solve a large class of partial differential equations.
  bio: |
    I am a mathematician and theoretical biologist at the University of California, Irvine. My programming language of choice is Julia and I am the lead developer of the JuliaDiffEq organization dedicated to solving differential equations (and includes the package DifferentialEquations.jl). My research is in time stepping methods for solving stochastic differential equations (SDEs) and applications to stochastic partial differential equations (SPDEs) which model biological development.
  resources:
    - name: "Repo"
      url: "https://github.com/JuliaDiffEq/DifferentialEquations.jl"
  id: 6

- speaker: "Juan Pablo Vielma"
  avatar: https://avatars2.githubusercontent.com/u/6369022?s=460&v=4
  affiliation: "MIT Sloan"
  title: "The JuMP ecosystem for mathematical optimization "
  type: workshop
  abstract: >
    JuMP is an award-winning DSL for mathematical optimization that has quickly become the gold-standard for its simplicity, performance, and versatility. A major overhaul of JuMP will be finalized during the JuMP-dev workshop in June, so it is the perfect time for an updated tutorial and feature demo.
  desc: |
    JuMP is a multi-award-winning domain-specific language for mathematical optimization. JuMP has already been successfully used in academic and industrial problems related to marketing, causal inference, daily fantasy sports, optimal control of aerial drones, machine learning, school bus routing, sustainable power systems expansion, and decarbonization of electrical networks. The JuMP ecosystem gives access to a wide range of highly-effective commercial and open-source optimization tools in a natural syntax that requires only a basic knowledge of mathematical optimization. JuMP provides this access with a performance that matches or exceeds those of commercial and open-source alternatives, as well as unparalleled versatility and extensibility allowed by the advanced features of the Julia language. In particular, JuMP and its infrastructure was used to develop the solver Pajarito.jl, which is currently the state-of-the-art for the class known as mixed-integer conic optimization problems. JuMP has recently received a major overhaul that should further facilitate the development of similar advanced optimization tools.

    In this tutorial, we begin with basic syntax and features of JuMP and associated packages assuming no previous knowledge of JuMP and only an elementary knowledge of mathematical optimization. We then cover more advanced features, give performance tips, and cover the recent improvements to JuMP developed in the second Annual JuMP-dev Workshop. Finally, we demo some state-of-the-art features, including showing how various packages in the rich Julia ecosystem can be seamlessly combined to provide simple solutions to complicated problems in the optimal control of aerial drones.
  bio: |
    Juan Pablo Vielma is an associate professor at MIT’s Sloan School of Management and is also associated to MIT’s Operations Research Center. Juan Pablo’s research interests include the development of theory and technology for mathematical optimization and their application to problems in marketing, statistics and sustainable management of energy and natural resources. Juan Pablo is the Ph.D. advisor of two of the creators of JuMP and continues to be closely involved in JuMP’s development. Some projects he is currently associated with are the Pajarito Solver, JuMP’s extension for piecewise linear optimization and the Cassette and Capstan tools.
  resources:
    - name: "Repo"
      url: "https://github.com/JuliaOpt/JuMP.jl"
  id: 7

- speaker: "Avik Sengupta"
  avatar: https://avatars1.githubusercontent.com/u/378918?s=460&v=4
  affiliation: "Julia Computing"
  title: "Natural Language Processing in Julia"
  type: workshop
  abstract: >
    A hands on workshop demonstrating the use of natural language processing tools in Julia. Working with textual data, we will discuss methods for data collection, parsing, pre-processing, embedding, classification and deep neural networks.
  desc: |
    In this hands on workshop, we will explore the use of natural language processing tools in Julia, with a particular focus on statistical machine learning based approaches. The content will be based primarily around the TextAnalysis.jl and Flux.jl packages. We will learn some of the primary algorithms in this area, and implement practical examples using these packages. The course will be aimed at someone who has a basic understanding of the Julia programming language, but no prior experience of natural language processing

    * Data Collection
        * Using existing corpora
        * Web scraping to collect your own data
        * Data storage and representation
    * Pre-processing
        * Stemming
        * Stopwords
    * Word representations
        * Bag of words, TF-IDF
        * Text Rank algorithm for summarisation
    * Word Embeddings
    * Deep neural networks for machine learning
        * Language Detection
        * Parsing
        * Text generation
  bio: |
    Avik has spent many years helping investment banks leverage technology in risk and capital markets. He’s worked on bringing AI powered solutions to investment research, and is currently the VP of Engineering at Julia Computing.
  resources:
    - name: "Repo"
      url: "https://github.com/JuliaText/TextAnalysis.jl"
  id: 8
